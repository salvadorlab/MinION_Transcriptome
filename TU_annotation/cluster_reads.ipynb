{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybedtools.bedtool as pybed\n",
    "import pybedtools\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import math\n",
    "from statistics import mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input and output dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "workdir=\"/scratch/rx32940/minION/polyA_directRNA/TU_Annotation\"\n",
    "\n",
    "input=os.path.join(workdir, \"input\")\n",
    "output=os.path.join(workdir, \"example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bam to bed\n",
    "- read in gene annotation file, which contains information about chromsome (\"chrom\"),gene start site (\"start\"), end site (\"end\"), strand (\"strand\"), gene locus tag (\"locus tag\"), gene name (\"name\") \n",
    "- read in bam/bed file (if bed file not exist, read bam and convert to bed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_file=os.path.join(input, \"GCF_000007685.1_gene_table.txt\") # gene annotation file\n",
    "\n",
    "bam=\"/scratch/rx32940/minION/polyA_cDNA/map/genome/bam/Copenhageni_Basecalled_Aug_16_2019_Direct-cDNA_PolyATail_rna_filtered.bam\"\n",
    "\n",
    " # bam\n",
    "bed_file=os.path.join(input, \"Copenhageni_Basecalled_Aug_16_2019_Direct-cDNA_PolyATail_rna_filtered.bed\") # bed\n",
    "\n",
    "if not os.path.isfile(bed_file): # if bed file not exist? convert from bam\n",
    "    bam = pybed.BedTool(bam)\n",
    "    bed=bam.bam_to_bed().to_dataframe()\n",
    "    bed.to_csv(bed_file,sep=\"\\t\", index = False)\n",
    "else: # read bed file\n",
    "    bed=pd.read_csv(bed_file, sep=\"\\t\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### process input files\n",
    "\n",
    "- only keep reads with mapping quality >=30\n",
    "- separate reads mapped to leading and lagging strand\n",
    "- read in gene annotations\n",
    "- separate genes on the leading and lagging strand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bed_filtered = bed#.loc[bed[\"score\"] >= 30] # filter read quality\n",
    "\n",
    "read_map_lead=bed_filtered.loc[bed[\"strand\"] == \"+\"]\n",
    "read_map_lag = bed_filtered.loc[bed[\"strand\"] == \"-\"]\n",
    "\n",
    "gene_anot=pd.read_csv(gene_file, sep=\"\\t\")\n",
    "\n",
    "lead_strand_genes = gene_anot.loc[gene_anot[\"strand\"] == \"+\"]\n",
    "lag_strand_genes = gene_anot.loc[gene_anot[\"strand\"] == \"-\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gene ORF aware TSS identification\n",
    "- input: \n",
    "    1) gene start codon annotation\n",
    "    2) bed file converted from bam alignment file\n",
    "- output: \n",
    "    1) potential TSS sites for each gene, number of reads at the each TSS site range, maximum end site stretch for all reads mapped at the site\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lead TSS with gene start codon annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 10 # the position of reads with start codon less than threshold are put into the same cluster \n",
    "\n",
    "chroms = gene_anot[\"genomic_accession\"].unique() # chromosomes in the genome\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get reads overlap at either \"start\" or \"end\" (start in lagging strand) of a gene\n",
    "def get_overlap_reads(read_mapped_cur_chrom, cur_chrom_gene ,gene, position):\n",
    "    \n",
    "    gene_start = int(cur_chrom_gene.loc[cur_chrom_gene[\"locus_tag\"]==gene,position]) # start codon of the current gene at 5' end\n",
    "    reads_before_start = read_mapped_cur_chrom.loc[read_mapped_cur_chrom[\"start\"] <= gene_start] # reads with start sites mapped before gene start codon\n",
    "    reads_overlap_start = reads_before_start.loc[reads_before_start[\"end\"] >= gene_start] # from reads start before start codon, get reads overlapped with the start codon (ends after start codon)\n",
    "    reads_overlap_start.reset_index(drop=True, inplace=True)\n",
    "    return reads_overlap_start\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tss_pos(reads_overlap, cluster_start, cluster_end,position):\n",
    "    start_list = reads_overlap.loc[cluster_start:cluster_end, \"start\"].tolist()\n",
    "    tss_start= mode(start_list) if start_list.count(mode(start_list)) > 2 else min(start_list)\n",
    "    end_list=reads_overlap.loc[cluster_start:cluster_end, \"end\"].tolist()\n",
    "    tss_end = mode(end_list) if end_list.count(mode(end_list)) > 2 else max(end_list)# find the end sites (read with furtherest mapping) of the current cluster\n",
    "    if position == \"start\":\n",
    "        return tss_start+1, tss_end\n",
    "    else:\n",
    "        return tss_end, tss_start+1\n",
    "            \n",
    "def cluster_tss(reads_overlap,position, gene_name, chrom):\n",
    "    cur_gene_tss_clusters = pd.DataFrame() # tss clusters at for current gene's start codon\n",
    "    \n",
    "    \n",
    "    reads_overlap = reads_overlap.sort_values(by=position) # sort all reads overlapped with current gene's start codon based on their start sites\n",
    "    reads_overlap.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "\n",
    "    cluster_start = 0 # start position of the cluster  \n",
    "    cluster_end = 0 # start position of the cluster  (not included)\n",
    "    for index in range(1,len(reads_overlap.iloc[:,1])):\n",
    "        current_read = reads_overlap.iloc[index]\n",
    "        if (current_read[position] - reads_overlap.loc[index-1,position]) <= threshold: # if the start sites of two reads are close enough \n",
    "            cluster_end += 1 # assign to the same cluster\n",
    "        else:# if the start site of reads are too distant from each other to be in the same cluster\n",
    "            tss_pos = get_tss_pos(reads_overlap,cluster_start, cluster_end , position)\n",
    "            cur_gene_tss_clusters = cur_gene_tss_clusters.append({\"chrom\" : cur_chrom,\"start\" : tss_pos[0], \"end\":tss_pos[1], \"gene\" : cur_gene,\"num_reads\":int(cluster_end - cluster_start)},ignore_index=True)\n",
    "            cluster_start =  cluster_end = index \n",
    "            index += 1\n",
    "\n",
    "\n",
    "    # the last tss cluster when rest of the reads didn't get to go into the else condition to write their cluster into the df\n",
    "    tss_pos = get_tss_pos(reads_overlap, cluster_start, cluster_end, position)\n",
    "    cur_gene_tss_clusters = cur_gene_tss_clusters.append({\"chrom\" : chrom,\"start\" : tss_pos[0], \"end\":tss_pos[1], \"gene\" : gene_name,\"num_reads\":int(cluster_end - cluster_start)},ignore_index=True)\n",
    "\n",
    "    return cur_gene_tss_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c4f94e0a38a4cefaf8f2b8a15303786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1682.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16162/2638105928.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcov_at_pos\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# if the gene was mapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mcur_gene_tss_clusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcluster_tss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreads_overlap_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"start\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_gene\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_chrom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mlead_gene_tss_clusters\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mlead_gene_tss_clusters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_gene_tss_clusters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_gene_tss_clusters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_reads\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcov_at_pos\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcur_gene_tss_clusters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_reads\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_16162/4132389093.py\u001b[0m in \u001b[0;36mcluster_tss\u001b[0;34m(reads_overlap, position, gene_name, chrom)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mcluster_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;31m# start position of the cluster  (not included)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreads_overlap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mcurrent_read\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreads_overlap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcurrent_read\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mreads_overlap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# if the start sites of two reads are close enough\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mcluster_end\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;31m# assign to the same cluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tu_annotation/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tu_annotation/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1566\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1568\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1570\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tu_annotation/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_ixs\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   3377\u001b[0m         \u001b[0;31m# irow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3378\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3379\u001b[0;31m             \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_xs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3381\u001b[0m             \u001b[0;31m# if we are a copy, mark as such\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tu_annotation/lib/python3.9/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mfast_xs\u001b[0;34m(self, loc)\u001b[0m\n\u001b[1;32m    952\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minterleaved_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mblk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tu_annotation/lib/python3.9/site-packages/pandas/core/internals/base.py\u001b[0m in \u001b[0;36minterleaved_dtype\u001b[0;34m(dtypes)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfind_common_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/tu_annotation/lib/python3.9/site-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mfind_common_type\u001b[0;34m(types)\u001b[0m\n\u001b[1;32m   1844\u001b[0m     \u001b[0;31m# None, type, _SupportsDtype, str, Tuple[Any, int], Tuple[Any, Union[int,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1845\u001b[0m     \u001b[0;31m# Sequence[int]]], List[Any], _DtypeDict, Tuple[Any, Any]]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1846\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_common_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tu_annotation/lib/python3.9/site-packages/numpy/core/numerictypes.py\u001b[0m in \u001b[0;36mfind_common_type\u001b[0;34m(array_types, scalar_types)\u001b[0m\n\u001b[1;32m    652\u001b[0m     \u001b[0mscalar_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscalar_types\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m     \u001b[0mmaxa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_can_coerce_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    655\u001b[0m     \u001b[0mmaxsc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_can_coerce_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscalar_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tu_annotation/lib/python3.9/site-packages/numpy/core/numerictypes.py\u001b[0m in \u001b[0;36m_can_coerce_all\u001b[0;34m(dtypelist, start)\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdtypelist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0mthisind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0mthisind\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0m__len_test_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m         \u001b[0mnewdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__test_types\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mthisind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0mnumcoerce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdtypelist\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnewdtype\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lead_gene_tss_clusters = pd.DataFrame()\n",
    "\n",
    "for cur_chrom in chroms:\n",
    "    \n",
    "    cur_chrom_gene = lead_strand_genes.loc[lead_strand_genes[\"genomic_accession\"] == cur_chrom]\n",
    "    cur_chrom_gene.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    read_mapped_cur_chrom = read_map_lead.loc[read_map_lead[\"chrom\"]== cur_chrom]\n",
    "    \n",
    "    for gene in tqdm(range(len(cur_chrom_gene.iloc[:,1]))): # iterate through all genes\n",
    "        cur_gene = cur_chrom_gene.loc[gene,\"locus_tag\"] # current gene name\n",
    "        reads_overlap_start = get_overlap_reads(read_mapped_cur_chrom, cur_chrom_gene ,cur_gene, \"start\")\n",
    "        cov_at_pos = len(reads_overlap_start.iloc[:,1]) # find the coverage of the current gene's start codon, (all the reads overlap at gene start codon)\n",
    "        \n",
    "        if cov_at_pos > 1: # if the gene was mapped\n",
    "            cur_gene_tss_clusters = cluster_tss(reads_overlap_start, \"start\", cur_gene, cur_chrom)\n",
    "            lead_gene_tss_clusters  = lead_gene_tss_clusters.append(cur_gene_tss_clusters[(cur_gene_tss_clusters[\"num_reads\"] >= (cov_at_pos * 0.3)) | (cur_gene_tss_clusters[\"num_reads\"] >= 3)])\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# block for testing\n",
    "# cur_chrom=\"NC_005823.1\"\n",
    "# cur_chrom_gene = lead_strand_genes.loc[lead_strand_genes[\"genomic_accession\"] == cur_chrom]\n",
    "# cur_chrom_gene.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# read_mapped_cur_chrom = read_map_lead.loc[read_map_lead[\"chrom\"]== cur_chrom]\n",
    "# gene=298\n",
    "# cur_gene = cur_chrom_gene.loc[gene,\"locus_tag\"]\n",
    "# reads_overlap_start = get_overlap_reads(read_mapped_cur_chrom, cur_chrom_gene ,cur_gene, \"start\")\n",
    "# cov_at_pos = len(reads_overlap_start.iloc[:,1])\n",
    "# if cov_at_pos > 1: # if the gene was mapped\n",
    "#     cur_gene_tss_clusters = cluster_tss(reads_overlap_start, \"start\",cur_gene ,cur_chrom)\n",
    "\n",
    "# cur_gene_tss_clusters[cur_gene_tss_clusters[\"num_reads\"] > cov_at_pos * 0.3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write lead strand tss annotation with start codon awareness into file\n",
    "lead_gene_tss_clusters[\"strand\"] = \"+\" # write lead strand gene's tss read clusters \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gene aware TSS annotation on lagging strand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_gene_tss_clusters = pd.DataFrame()\n",
    "\n",
    "for cur_chrom in chroms:\n",
    "    \n",
    "    cur_chrom_gene = lag_strand_genes.loc[lag_strand_genes[\"genomic_accession\"] == cur_chrom]\n",
    "    cur_chrom_gene.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    read_mapped_cur_chrom = read_map_lag.loc[read_map_lag[\"chrom\"]== cur_chrom]\n",
    "    \n",
    "    for gene in tqdm(range(len(cur_chrom_gene.iloc[:,1]))): # iterate through all genes\n",
    "        cur_gene = cur_chrom_gene.loc[gene,\"locus_tag\"] # current gene name\n",
    "        reads_overlap_end = get_overlap_reads(read_mapped_cur_chrom, cur_chrom_gene ,cur_gene, \"end\")\n",
    "        cov_at_pos = len(reads_overlap_end.iloc[:,1]) # find the coverage of the current gene's start codon, (all the reads overlap at gene start codon)\n",
    "        \n",
    "        if cov_at_pos > 1: # if the gene was mapped\n",
    "            cur_gene_tss_clusters = cluster_tss(reads_overlap_end, \"end\", cur_gene, cur_chrom)\n",
    "\n",
    "        lag_gene_tss_clusters  = lag_gene_tss_clusters.append(cur_gene_tss_clusters[cur_gene_tss_clusters[\"num_reads\"] > cov_at_pos * 0.3])\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_gene_tss_clusters[\"strand\"]=\"-\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_aware_tss = pd.concat([lead_gene_tss_clusters, lag_gene_tss_clusters], ignore_index = True)\n",
    "\n",
    "gene_aware_tss = gene_aware_tss.dropna() # remove nan in the dataframe\n",
    "gene_aware_tss= gene_aware_tss.loc[gene_aware_tss[\"num_reads\"] > 2]\n",
    "\n",
    "gene_aware_tss= gene_aware_tss.astype({'start':int, 'end':int, \"num_reads\":int})\n",
    "gene_aware_tss.to_csv(os.path.join(output,\"gene_aware_tss.tab\"), sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TSS without gene start codon annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identification of TSS with no annotation\n",
    "\n",
    "read_map_lead = bed_filtered.loc[bed_filtered[\"strand\"] == \"+\"]\n",
    "read_map_lag = bed_filtered.loc[bed_filtered[\"strand\"] == \"-\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            \n",
    "def cluster_tss_unaware(cur_chrom_reads,position):\n",
    "    cur_tss_clusters = pd.DataFrame()\n",
    "    cluster_start = 0 # start position of the cluster  \n",
    "    cluster_end = 0 # start position of the cluster  (not included)\n",
    "    for index in tqdm(range(1,len(cur_chrom_reads.iloc[:,1]))): # loop through reads\n",
    "        current_read = cur_chrom_reads.iloc[index]\n",
    "        if (current_read[position] - cur_chrom_reads.loc[index-1,position]) <= threshold: # if the start sites of two reads are close enough \n",
    "            cluster_end += 1 # assign to the same cluster\n",
    "        else:# if the start site of reads are too distant from each other to be in the same cluster\n",
    "            tss_pos = get_tss_pos(cur_chrom_reads,cluster_start, cluster_end , position)\n",
    "            cur_tss_clusters = cur_tss_clusters.append({\"chrom\" : cur_chrom,\"start\" : tss_pos[0], \"end\":tss_pos[1], \"name\":\"gene_unaware\",\"num_reads\":int(cluster_end - cluster_start  + 1)},ignore_index=True)\n",
    "            cluster_start = cluster_end = index \n",
    "            index += 1\n",
    "\n",
    "    # the last tss cluster when rest of the reads didn't get to go into the else condition to write their cluster into the df\n",
    "    tss_pos = get_tss_pos(cur_chrom_reads, cluster_start, cluster_end, position)\n",
    "    cur_tss_clusters = cur_tss_clusters.append({\"chrom\" : cur_chrom,\"start\" : tss_pos[0], \"end\":tss_pos[1], \"name\":\"gene_unaware\",\"num_reads\":int(cluster_end - cluster_start  + 1)},ignore_index=True)\n",
    "\n",
    "    return cur_tss_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tss_clusters = pd.DataFrame() # tss clusters at for all reads' start codon\n",
    "\n",
    "\n",
    "for cur_chrom in chroms:\n",
    "    \n",
    "    # read mapped to one chromosome\n",
    "    read_map_cur_chrom_lead = read_map_lead.loc[read_map_lead[\"chrom\"] == cur_chrom]\n",
    "\n",
    "    read_map_cur_chrom_lead = read_map_cur_chrom_lead.sort_values(by=\"start\") # sort all reads overlapped with current gene's start codon based on their start sites\n",
    "    read_map_cur_chrom_lead.reset_index(drop=True, inplace = True)\n",
    "    cur_tss_clusters = cluster_tss_unaware(read_map_cur_chrom_lead, \"start\")\n",
    "\n",
    "    tss_clusters =tss_clusters.append(cur_tss_clusters ,ignore_index=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # this block is used for testing\n",
    "# read_map_cur_chrom_lead = read_map_lead.loc[read_map_lead[\"chrom\"] == cur_chrom]\n",
    "# read_map_cur_chrom_lead = read_map_cur_chrom_lead.sort_values(by=\"start\")\n",
    "# read_map_cur_chrom_lead.reset_index(drop=True, inplace = True)\n",
    "# index=91925\n",
    "# current_read = read_map_cur_chrom_lead.iloc[index]\n",
    "# cur_tss_clusters = pd.DataFrame()\n",
    "# cluster_start = 0 # start position of the cluster  \n",
    "# cluster_end = 0 # start position of the cluster  (not included)\n",
    "# for index in tqdm(range(index,91980)): # loop through reads\n",
    "#     current_read = read_map_cur_chrom_lead.iloc[index]\n",
    "#     if (current_read[\"start\"] - read_map_cur_chrom_lead.loc[index-1,\"start\"]) <= threshold: # if the start sites of two reads are close enough \n",
    "#         cluster_end += 1 # assign to the same cluster\n",
    "#     else:# if the start site of reads are too distant from each other to be in the same cluster\n",
    "#         tss_pos = get_tss_pos(read_map_cur_chrom_lead,cluster_start, cluster_end , \"start\")\n",
    "#         cur_tss_clusters = cur_tss_clusters.append({\"chrom\" : cur_chrom,\"start\" : tss_pos[0], \"end\":tss_pos[1], \"name\":\"gene_unaware\",\"num_reads\":int(cluster_end - cluster_start  + 1)},ignore_index=True)\n",
    "#         cluster_start = cluster_end = index \n",
    "#         index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_tss_clusters = tss_clusters\n",
    "lead_tss_clusters.reset_index(drop=True, inplace = True)\n",
    "lead_tss_clusters[\"strand\"] = \"+\"\n",
    "lead_tss_clusters= lead_tss_clusters.astype({'start':int, 'end':int, \"num_reads\":int})\n",
    "lead_tss_clusters.to_csv(os.path.join(output, \"lead.strand.tss.gene.unaware.bed\"), sep=\"\\t\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tss_clusters = pd.DataFrame() # tss clusters at for all reads' start codon (lagging strand at 3' end)\n",
    "\n",
    "\n",
    "for cur_chrom in chroms:\n",
    "    \n",
    "    # read mapped to one chromosome\n",
    "    read_map_cur_chrom_lag = read_map_lag.loc[read_map_lag[\"chrom\"] == cur_chrom]\n",
    "\n",
    "    read_map_cur_chrom_lag = read_map_cur_chrom_lag.sort_values(by=\"end\") # sort all reads overlapped with current gene's start codon based on their start sites\n",
    "    read_map_cur_chrom_lag.reset_index(drop=True, inplace = True)\n",
    "    cur_tss_clusters = cluster_tss_unaware(read_map_cur_chrom_lag, \"end\")\n",
    "\n",
    "    tss_clusters =tss_clusters.append(cur_tss_clusters ,ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_tss_clusters = tss_clusters\n",
    "lag_tss_clusters.reset_index(drop=True, inplace = True)\n",
    "lag_tss_clusters[\"strand\"] = \"-\"\n",
    "lag_tss_clusters= lag_tss_clusters.astype({'start':int, 'end':int, \"num_reads\":int})\n",
    "lag_tss_clusters.to_csv(os.path.join(output, \"lag.strand.tss.gene.unaware.bed\"), sep=\"\\t\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_unaware_tss= pd.concat([lead_tss_clusters,lag_tss_clusters], ignore_index = True)\n",
    "gene_unaware_tss.to_csv(os.path.join(output, \"tss.gene.unaware.tab\"), sep=\"\\t\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter gene unaware TSS based on cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate reads mapped to leading and lagging strand in the input bam file\n",
    "lead_bed = bed_filtered.loc[bed[\"strand\"] == \"+\"]\n",
    "lag_bed = bed_filtered.loc[bed[\"strand\"] == \"-\"]\n",
    "\n",
    "# write reads mapped to each bam file in bed (separate file for each stand)\n",
    "lead_bed.to_csv(os.path.join(output, \"bamtobed_lead.bed\"), header=False,sep=\"\\t\", index=False)\n",
    "lag_bed.to_csv(os.path.join(output, \"bamtobed_lag.bed\"), header=False,sep=\"\\t\", index = False)\n",
    "\n",
    "# use bed tools to read in each strand's bed file\n",
    "lead_bam_bed = pybed.BedTool(os.path.join(output, \"bamtobed_lead.bed\"))\n",
    "lag_bam_bed = pybed.BedTool(os.path.join(output, \"bamtobed_lag.bed\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate coverage at each base for each strand (use bedtools genome_coverage)\n",
    "lead_bam_cov = lead_bam_bed.genome_coverage(g=os.path.join(input, \"GCA_000007685.1_genome_file.txt\"), d=True)\n",
    "lag_bam_cov = lag_bam_bed.genome_coverage(d=True,g=os.path.join(input, \"GCA_000007685.1_genome_file.txt\"))\n",
    "\n",
    "lead_bam_cov_df = pd.read_table(lead_bam_cov.fn, names =[ \"chrom\", \"start\", \"cov\"] )\n",
    "lag_bam_cov_df = pd.read_table(lag_bam_cov.fn, names=[\"chrom\", \"start\", \"cov\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write per-base cov to bed file\n",
    "lead_bam_cov_df.to_csv(os.path.join(output, \"bamtobed_lead_cov.bed\"), header=False,sep=\"\\t\", index=False)\n",
    "lag_bam_cov_df.to_csv(os.path.join(output, \"bamtobed_lag_cov.bed\"), header=False,sep=\"\\t\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is unaware tss sites get from previous \n",
    "# lead_tss_clusters = pd.read_csv(os.path.join(output, \"lead.strand.tss.gene.unaware.bed\"),sep=\"\\t\",index_col=False) # can delete later\n",
    "# lag_tss_clusters = pd.read_csv(os.path.join(output, \"lag.strand.tss.gene.unaware.bed\"),sep=\"\\t\",index_col=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cov of the site of each detected tss\n",
    "lead_unaware_tss_start_cov = lead_tss_clusters.merge(lead_bam_cov_df,how=\"left\", on=[\"chrom\", \"start\"]) \n",
    "lead_unaware_tss_filtered= lead_unaware_tss_start_cov.loc[lead_unaware_tss_start_cov[\"num_reads\"] >= lead_unaware_tss_start_cov[\"cov\"]]\n",
    "\n",
    "\n",
    "lag_unaware_tss_start_cov = lag_tss_clusters.merge(lag_bam_cov_df,how=\"left\", on=[\"chrom\", \"start\"]) \n",
    "lag_unaware_tss_filtered= lag_unaware_tss_start_cov.loc[lag_unaware_tss_start_cov[\"num_reads\"] >= lag_unaware_tss_start_cov[\"cov\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine lead and lag strand, write filtered tss to file\n",
    "lead_unaware_tss_filtered.reset_index(drop=True, inplace=True)\n",
    "lag_unaware_tss_filtered.reset_index(drop=True, inplace=True)\n",
    "gene_unaware_tss_filtered= pd.concat([lead_unaware_tss_filtered, lag_unaware_tss_filtered])\n",
    "gene_unaware_tss_filtered.to_csv(os.path.join(output,\"gene_unaware_tss_filtered.tab\"), sep = \"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine gene aware and unaware TSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can delete\n",
    "# gene_aware_tss = pd.read_csv(os.path.join(output, \"gene_aware_tss.tab\"), index_col=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_approaches = gene_unaware_tss_filtered[[\"chrom\",\"start\", \"end\", \"strand\"]].merge(gene_aware_tss, how=\"outer\", on=[\"chrom\",\"start\",\"strand\"])\n",
    "combine_approaches[\"end\"] = combine_approaches.apply(lambda row: row[\"end_y\"] if math.isnan(row[\"end_x\"]) else row[\"end_x\"],axis=1)\n",
    "combine_approaches_edited = combine_approaches.drop([\"end_x\", \"end_y\",\"num_reads\"],axis=1)\n",
    "combine_approaches_edited = combine_approaches_edited.astype({\"start\":int, \"end\":int})\n",
    "combine_approaches_edited.to_csv(os.path.join(output, \"combined_tss.tab\"), index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_approaches.apply(lambda row: math.is_nan(row[\"end_y\"]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input=\"/scratch/rx32940/minION/polyA_directRNA/TU_Annotation/input\"\n",
    "output=\"/scratch/rx32940/minION/polyA_directRNA/TU_Annotation/example\"\n",
    "# gene file with the annotated genes, a table where chromosome is in the first column, start codon position in the fourth column, stop codon in the fifth, sign in the seventh, name in the ninth\n",
    "gene_file = os.path.join(input, \"GCF_000007685.1_gene_table_test.txt\")\n",
    "#input file is a bed file generated from sorted bam alignment file using bedtools bamtobed\n",
    "input_file = os.path.join(input, \"Copenhageni_Basecalled_Aug_16_2019_Direct-cDNA_NoPolyATail_rna_filtered_test.bed\")\n",
    "output_file_aware = os.path.join(output, \"test.gene_aware.tab\")\n",
    "#threshold is in general dependent on the sequencing depth\n",
    "threshold = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(gene_file, 'r') as gen, open(input_file, 'r') as bed, open(output_file_aware, 'w') as new:\n",
    "    all_reads_neg = {'NC_005823.1': [], 'NC_005824.1': []}  # both genes and reads in their chromosome\n",
    "    all_reads_pos = {'NC_005823.1': [], 'NC_005824.1': []}\n",
    "    genes = {'NC_005823.1': [], 'NC_005824.1': []} #only genes\n",
    "    for line in gen: #store genes coordinates first\n",
    "        read = line.strip().split(\"\\t\")\n",
    "        if read[6] == '-':\n",
    "            all_reads_neg[read[0]].append((int(read[3]), int(read[4]), read[8], 0)) #zero in the end indicates that it is a gene not a read\n",
    "        else:\n",
    "            all_reads_pos[read[0]].append((int(read[3]), int(read[4]), read[8], 0))\n",
    "    \n",
    "\n",
    "all_reads_pos['NC_005823.1'][0:10]\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(gene_file, 'r') as gen, open(input_file, 'r') as bed, open(output_file_aware, 'w') as new:\n",
    "    for line in bed: #store reads coordinates\n",
    "        read = line.strip().split()\n",
    "        if read[5] == '-':\n",
    "            all_reads_neg[read[0]].append((int(read[1]), int(read[2]), 'read', 1, 1)) #1 to indicate it is a read not a gene\n",
    "        else:\n",
    "            all_reads_pos[read[0]].append((int(read[1]), int(read[2]), 'read', 1, 1))\n",
    "# all_reads_pos['NC_005823.1'][len(all_reads_pos['NC_005823.1'])-5: len(all_reads_pos['NC_005823.1'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reads_pos['NC_005823.1'][len(all_reads_pos['NC_005823.1'])-5: len(all_reads_pos['NC_005823.1'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(gene_file, 'r') as gen, open(input_file, 'r') as bed, open(output_file_aware, 'w') as new:\n",
    "    for ch in all_reads_pos: #process positive reads and genes seperately from negative ones\n",
    "            chromosome = all_reads_pos[ch]\n",
    "            chromosome.sort() #sort genes and reads according to their start site\n",
    "            read_index = 0\n",
    "            prev_gene = 0\n",
    "            for read in chromosome: #read here can be either a gene or a read\n",
    "                if read[-1] == 0: # stop if it is a gene\n",
    "                    before = list(chromosome[0:read_index]) #take the reads before the start codon\n",
    "                    before.sort(key=lambda before: before[1]) #sort them accoding to their end site\n",
    "                    end = before[-1][1] #the furthest end\n",
    "                    if end > read[0]: # if it is after the start codon i.e. read overlaps the start codon\n",
    "                        after_index = len(before) - 1\n",
    "                        # take reads until their end bcome less than the start codon (don't overlap the start codon anymore = )\n",
    "                        while end > read[0] and after_index > 0:\n",
    "                            after_index -= 1 #move to the next read\n",
    "                            end = before[after_index][1] #set the end of the next read, it will be checked in the next round of the while function\n",
    "                        after = list(before[after_index:])# Only the reads that overlap the start codon\n",
    "                        #now resolve if their multiple peaks\n",
    "                        current = list()\n",
    "                        ends = list()\n",
    "                        cov = len(after) # the coverage at the start codon is the number of overlapping reads\n",
    "                        after.sort() #sort again according to the start site\n",
    "                        prev = after[0][0]\n",
    "                        for end in after: #end is actually the read not just an end\n",
    "                            if end[0] - prev < threshold: #if the distance between the read start site and the next one is less than the threshold, take in the same cluster\n",
    "                                current.append(end[0])\n",
    "                                ends.append(end[1])\n",
    "                                prev = end[0]\n",
    "                            else:\n",
    "                                if len(current) > (0.3 * cov):  # if the read is far from than the next one, finish the current cluster and check it if its count is important\n",
    "                                    ends.sort() # optional step to calculate the end of these start sites\n",
    "                                    tss_end = ends[-1] # the end is the most extrem end\n",
    "                                    new.write('%s\\t%i\\t%i\\t%s\\t+\\t%i\\n' % (ch, current[0] + 1, len(current), read[2], tss_end))\n",
    "                                current = [end[0]] #start a new cluster with the current read\n",
    "                                ends = [end[1]]\n",
    "                                prev = end[0]\n",
    "                    if len(current) > (0.3 * cov) and len(current) > 2: #to check the last cluster\n",
    "                        # print(read[2])\n",
    "                        ends.sort()\n",
    "                        tss_end = ends[-1]\n",
    "                        new.write('%s\\t%i\\t%i\\t%s\\t+\\t%i\\n' % (ch, current[0] + 1, len(current), read[2], tss_end))\n",
    "                read_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(gene_file, 'r') as gen, open(input_file, 'r') as bed, open(output_file_aware, 'a') as new:\n",
    "    for ch in all_reads_neg: #similar to above but designed for negative reads\n",
    "            chromosome = all_reads_neg[ch]\n",
    "            chromosome.sort(key=lambda chromosome: chromosome[1])\n",
    "            read_index = 0\n",
    "            for read in chromosome:\n",
    "                if read[-1] == 0:\n",
    "                    # after_idx = read_index\n",
    "                    current = list()\n",
    "                    for i in chromosome[read_index + 1:]:\n",
    "                        if i[0] > read[1]:\n",
    "                            break\n",
    "                        elif i[1] > read[1]:\n",
    "                            current.append((i[1], i[0]))  # i[1]\n",
    "                    if len(current) > 0:\n",
    "\n",
    "                        current.sort()\n",
    "                        prev = current[0][0]\n",
    "                        cov = len(current)\n",
    "                        curr = list()\n",
    "                        ends = list()\n",
    "                        for i in current:\n",
    "                            if (i[0] - prev) < 10:\n",
    "                                curr.append(i[0])\n",
    "                                prev = i[0]\n",
    "                                ends.append(i[1])\n",
    "                            else:\n",
    "                                if len(curr) > (0.3 * cov):\n",
    "                                    ends.sort()\n",
    "                                    tss_end = ends[0]\n",
    "                                    new.write('%s\\t%i\\t%i\\t%s\\t-\\t%i\\n' % (ch, curr[-1] + 1, len(curr), read[2], tss_end))\n",
    "                                curr = [i[0]]\n",
    "                                prev = i[0]\n",
    "                        if len(curr) > (0.3 * cov) and len(curr) > 2:\n",
    "                            ends.sort()\n",
    "                            tss_end = ends[0]\n",
    "                            new.write('%s\\t%i\\t%i\\t%s\\t-\\t%i\\n' % (ch, curr[-1] + 1, len(curr), read[2], tss_end))\n",
    "                read_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identification of TSS with no annotation\n",
    "intermediate_file = os.path.join(output, \"TSS_id_no_annotation\")\n",
    "#input file is a bed file generated from sorted bam alignment file using bedtools bamtobed\n",
    "input_file = input_file\n",
    "with open(input_file, 'r') as old, open(intermediate_file, 'w') as new:\n",
    "    pos_reads = {'NC_005823.1': [], 'NC_005824.1': []} #seperate positive from negative reads\n",
    "    neg_reads = {'NC_005823.1': [], 'NC_005824.1': []}\n",
    "    for line in old:\n",
    "        read = line.strip().split()\n",
    "        if read[-1] == '+':\n",
    "            pos_reads[read[0]].append(int(read[1]))\n",
    "        else:\n",
    "            neg_reads[read[0]].append(int(read[2]))\n",
    "    for chromosome in pos_reads:\n",
    "        chromo = pos_reads[chromosome]\n",
    "        chromo.sort()\n",
    "        prev = chromo[0]\n",
    "        current = [chromo[0]]\n",
    "        for site in chromo[1:]:\n",
    "            if site - prev < threshold:\n",
    "                current.append(site)\n",
    "                prev = site\n",
    "            else:\n",
    "                if len(current) > 3: #if the cluster is more than three reads considere it for further analysis\n",
    "                    new.write('%s\\t%i\\t%i\\t%i\\t+\\n' % (chromosome, current[0]+1, len(current), current[-1] - current[0]))\n",
    "                prev = site\n",
    "                current = [site]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_unaware = os.path.join(output,'filtered_TSS_unaware.tab')\n",
    "pos_cov = os.path.join(output,'bamtobed_lead_cov.bed')\n",
    "neg_cov = os.path.join(output,'bamtobed_lag_cov.bed')\n",
    "\n",
    "with open(intermediate_file, 'r') as old, open(output_file_unaware, 'w') as new, open(pos_cov, 'r') as pos, open(neg_cov, 'r') as neg:\n",
    "    coverage = {'-': {'NC_005823.1': [], 'NC_005824.1': []}, '+': {'NC_005823.1': [], 'NC_005824.1': []}} #store coverage\n",
    "    for line in pos:\n",
    "        read = line.strip().split()\n",
    "        coverage['+'][read[0]].append(int(read[2]))\n",
    "    for line in neg:\n",
    "        read = line.strip().split()\n",
    "        coverage['-'][read[0]].append(int(read[2]))\n",
    "    for line in old:\n",
    "        read = line.strip().split()\n",
    "        if int(read[2]) > coverage[read[-1]][read[0]][int(read[1])]:  # if cluster meet the coverage criteria leave it, else don't print it\n",
    "            new.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage[read[-1]][read[0]][int(983)]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "57dd241cb148cc0f6cdd2944948ec59dd0e7c7de5bd15212d71dc7338efa6ab0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('tu_annotation': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
